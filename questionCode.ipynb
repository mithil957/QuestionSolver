{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "#imports the google cloud lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html.parser as htmlparser #corrects html text to normal text\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer #nlp module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = 'CUSTOM_SEARCH_ENEGINE_ID'\n",
    "key = 'GOOGLE_VISION_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:\\\\Users\\\\rajes\\\\Python_Projects\\\\QuestionBot\\\\vision_key.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hq - appends logical AND to added search terms \n",
    "# hl - sets user interface language\n",
    "# num - how many results to return\n",
    "# sort - sort expression to apply to results\n",
    "# start - index of first return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up(yourQuestion): \n",
    "    url = 'https://www.googleapis.com/customsearch/v1' #need to attach this url so it can connect it with google API\n",
    "    parameter = {'q':yourQuestion,'cx':cx,'key':key,} #dict of the question being asked, engine_ID, API_key(lets you use the API)\n",
    "    result_page = requests.request('GET',url,params= parameter) #sends a HTTP request to get search results  \n",
    "    results_json = json.loads(result_page.text) #loads the results into JSON format\n",
    "    \n",
    "    links = [item['link'] for item in results_json['items']] #list comprehension to turn all 'link' data into a list\n",
    "    df = pd.DataFrame(links, columns=['link']) #makes a Dataframe with the columns mapped to the 'links' list\n",
    "    df['title'] = [item['title'] for item in results_json['items']] #adds 'title' data to Dataframe\n",
    "    df['htmlSnippet'] = [item['htmlSnippet'] for item in results_json['items']] #adds 'htmlSnippet' data to Dataframe\n",
    "    \n",
    "    if(int(results_json['searchInformation']['totalResults']) > 10): \n",
    "        #check to see if there are more than 10 results\n",
    "        next_index = results_json['queries']['nextPage'][0]['startIndex'] \n",
    "        #sets the index at 10 so we get another 10 results, the reason why we change have to do this is b/c this method only returns\n",
    "        #10 results, there is another method below which returns any number of results \n",
    " \n",
    "        #---------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        #code here is all the same as above but just with the data from the next 10 results(or data on the next page)\n",
    "        para1 = {'q':yourQuestion,'cx':cx,'key':key,'start':next_index} \n",
    "    \n",
    "        page1 = requests.request('GET',url,params= para1)\n",
    "        results1 = json.loads(page1.text)\n",
    "    \n",
    "        links1 = [item['link'] for item in results1['items']]\n",
    "        df1 = pd.DataFrame(links1, columns=['link'])\n",
    "        df1['title'] = [item['title'] for item in results1['items']]\n",
    "        df1['htmlSnippet'] = [item['htmlSnippet'] for item in results1['items']]\n",
    "    \n",
    "        data = pd.concat([df,df1],ignore_index=True) #merges the two dataframes \n",
    "        return data\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way of getting search results\n",
    "#source : https://stackoverflow.com/questions/41032472/how-to-query-an-advanced-search-with-google-customsearch-api\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "import pprint\n",
    "\n",
    "my_api_key = key\n",
    "my_cse_id = cx\n",
    "\n",
    "def google_search(search_term, api_key, cse_id, **kwargs):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()\n",
    "    return res['items']\n",
    "\n",
    "results = google_search(\n",
    "    'stackoverflow site:en.wikipedia.org', my_api_key, my_cse_id, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(file_name):\n",
    "    #finds text in file\n",
    "    client = vision.ImageAnnotatorClient() #make a client\n",
    "    \n",
    "    with open(file_name,'rb') as image_file: #grabs the image givin the title\n",
    "        content = image_file.read()\n",
    "        \n",
    "    image = types.Image(content = content) #loads image into memory\n",
    "    \n",
    "    response = client.text_detection(image = image)\n",
    "    texts = response.text_annotations\n",
    "    #prefroms text detection\n",
    "    \n",
    "    return texts[0].description.split('\\n')\n",
    "    #texts -> is returns a list, the frist index of the list contains\n",
    "    #description, which can split be based on the \\n, this yields \n",
    "    #the Question and the Answer choices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(text):\n",
    "    text = [x.lower() for x in text] #lower-cases the whole list\n",
    "    text = text[:-1] #gets rid of the last index, the last index contained '', which has no use\n",
    "    \n",
    "    \n",
    "    for x in text: #this loop is for finding out which indices does the question takes up\n",
    "        if '?' in x: #look for '?' in text[x]\n",
    "            index = text.index(x) + 1 #once it finds the first instance of a '?' then it breaks the loop\n",
    "            break\n",
    "    #There could be a flaw here, b/c if the question had another ? in it, then that messes up the code\n",
    "    \n",
    "    text[0:index] = [' '.join(text[0:index])] #join the all the indices up until the one with a '?' in it\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_into_search_string(question):#has to be question with 3 multiple choices, in a list\n",
    "    search_string = '{} AND ({} | {} | {})'.format(question[0],question[1],question[2],question[3])\n",
    "    return search_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns all the strings in the dataframe columns lowercase, making it lowercase helps with the search\n",
    "def turn_into_lower_case(df): \n",
    "    df['title'] = df['title'].apply(lambda x: x.lower()) \n",
    "    df['htmlSnippet'] = df['htmlSnippet'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_answers(data,q):\n",
    "    parser = htmlparser.HTMLParser() #gets rid of apostrophes \n",
    "    i = 0\n",
    "    while(i<len(data)):\n",
    "        x = parser.unescape(data['htmlSnippet'][i])\n",
    "        data['htmlSnippet'][i] = x.replace(\"'\",\"\")\n",
    "        i += 1\n",
    "    \n",
    "    st = LancasterStemmer() #gets of plural words\n",
    "    words = [st.stem(i) for i in q[1:]]\n",
    "    \n",
    "    \n",
    "    count_list = []\n",
    "    for choice in words:\n",
    "        choice = choice.replace(\"'\",\"\")\n",
    "        a = data['title'].apply(lambda x: x.count(choice)).sum() + data['htmlSnippet'].apply(lambda x: x.count(choice)).sum()\n",
    "        count_list.append(a)\n"
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the question and frequency of the answer choices. Works only for three choices, so far. \n",
    "def print_count(count_list,q):\n",
    "    print('{}\\n{} : {} \\n{} : {}\\n{} : {}'.format(q[0],q[1],count_list[0],q[2],count_list[1],q[3],count_list[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer():\n",
    "    file_title = input() #asks for user input of the file\n",
    "    file_name = file_title + '.PNG' #adds a png to the end\n",
    "    question_list = detect_text(file_name) # finds text on it\n",
    "    question_list = clean_up(question_list) #cleans up the text list returned\n",
    "    searchable_string = turn_into_search_string(question_list) #turns question list into a search string\n",
    "    df = look_up(searchable_string) #searchs web and collects the data\n",
    "    turn_into_lower_case(df) #turns a part of the dataframe lowercase\n",
    "    count_of_choices = count_answers(df,question_list) #counts up the choices found and compiles them into a list\n",
    "    print_count(count_of_choices,question_list) #prints out the choice with the count number next to it\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same method as above but contains all the data, so user can mess around with it or something \n",
    "\n",
    "def get_answer_with_data():\n",
    "    file_title = input() #asks for user input of the file(name of file in local folder) or you change to specify certain PATH\n",
    "    file_name = file_title + '.PNG' #adds a png to the end, you can change to match whatever photo format you need\n",
    "    question_list = detect_text(file_name) # finds text on it\n",
    "    question_list = clean_up(question_list) #cleans up the text list returned\n",
    "    searchable_string = turn_into_search_string(question_list) #turns question list into a search string\n",
    "    df = look_up(searchable_string) #searchs web and collects the data\n",
    "    turn_into_lower_case(df) #turns a part of the dataframe lowercase\n",
    "    count_of_choices = count_answers(df,question_list) #counts up the choices found and compiles them into a list\n",
    "    print_count(count_of_choices,question_list) #prints out the choice with the count number next to it\n",
    "    return [file_name,question_list,searchable_string,df,count_of_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1\n",
      "which of these bodies of water is the smallest?\n",
      "pond : 5 \n",
      "sea : 15\n",
      "ocean : 45\n"
     ]
    }
   ],
   "source": [
    "get_answer() #Incorrect - Pond is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2\n",
      "what is the act of performing music in public places for tips?\n",
      "busking : 56 \n",
      "straw-capping : 0\n",
      "panhandling : 4\n"
     ]
    }
   ],
   "source": [
    "get_answer()#Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q3\n",
      "which novel popularized the term \"avatar\" in the current sense?\n",
      "the player of games : 0 \n",
      "snow crash : 9\n",
      "neuromancer : 2\n"
     ]
    }
   ],
   "source": [
    "get_answer()#Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q10\n",
      "the asian delicacy known as bird's nest soup is made primarily from what?\n",
      "birds' nests : 16 \n",
      "fried noodles : 3\n",
      "shredded cabbage : 2\n"
     ]
    }
   ],
   "source": [
    "get_answer()#Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q11\n",
      "according to the u.s. government, which of tese is correct?\n",
      "daylight saving time : 35 \n",
      "daylight savings time : 4\n",
      "daylight saving's time : 4\n"
     ]
    }
   ],
   "source": [
    "get_answer()#Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q12\n",
      "which of these cities has the biggest bike share program?\n",
      "paris : 0 \n",
      "amsterdam : 1\n",
      "new york : 15\n"
     ]
    }
   ],
   "source": [
    "get_answer()#Incorrect - Paris is right"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
